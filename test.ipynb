{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74f0e82-b52f-4206-ac39-c130d67ff6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(),\"..\")))\n",
    "from TextClassification import Augment\n",
    "from TextClassification import TextPreprocess\n",
    "from TextClassification import ExtractKeyword\n",
    "from TextClassification import TextVector\n",
    "from TextClassification import FeatureDimensionReduce\n",
    "from TextClassification import FeatureCode\n",
    "from TextClassification import ModelPreparation\n",
    "from TextClassification import Classifier\n",
    "from TextClassification import Successor\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import json\n",
    "from fastcore.transform import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7b7a2-0c5a-4721-a9db-f7d52106754c",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "150837a1-94ef-41a0-bf57-5a1be5cbe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getcwd()+'/data/训练集.csv')[:1000]\n",
    "data['feature'] = data['评论标题'].map(str)+data['评论内容'].map(str)\n",
    "data_feature = data['feature']\n",
    "\n",
    "data_predict_origin = pd.read_csv(os.getcwd()+'/data/测试集.csv')[:1000]\n",
    "data_predict_origin['feature'] = data_predict_origin['评论标题'].map(str)+data_predict_origin['评论内容'].map(str)\n",
    "data_predict_feature = data_predict_origin['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40f4da67-ed1e-484e-8c97-1e2bafadcf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label对应关系: {4.0: 3, 5.0: 4, 1.0: 0, 3.0: 2, 2.0: 1}\n"
     ]
    }
   ],
   "source": [
    "# 加载label_array\n",
    "data['label'] = preprocessing.LabelEncoder().fit_transform(data['评分'])\n",
    "label_array = np.array(data['label'])\n",
    "# label与类别的映射关系\n",
    "label_map = dict(zip(data['评分'].unique(),preprocessing.LabelEncoder().fit_transform(data['评分'].unique())))\n",
    "print('label对应关系:',label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af4e02ad-80e6-4db5-895b-8e3bc3e7397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_cy = list(pd.read_csv(os.getcwd()+'/data/define_stopwords.txt',names = ['word'], \n",
    "                                sep = 'aaa',encoding = 'UTF-8',engine='python').word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb96f148-5971-41e4-a56e-e3ec2ac17312",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_file = open(os.getcwd()+'/data/parameter.json', \"rb\")\n",
    "parameter_json = json.load(parameter_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f938c8d4-d314-4a04-a5a4-f5747b4e10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建input_data\n",
    "input_data = {}\n",
    "input_data['data_feature'] = data_feature\n",
    "input_data['stop_words'] = stopwords_cy\n",
    "input_data['label_array'] = label_array\n",
    "input_data['aug_mark'] = np.array([0 for i in range(len(label_array))])\n",
    "input_data['parameter'] = parameter_json\n",
    "input_data['data_predict_feature'] = data_predict_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9367ec2-7851-4295-a704-d2b686b6b1d6",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "995eb6a3-9db0-4fa0-b5c3-759d20fea1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 16:06:19,512 : INFO : 文体转换已完成\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1215.58it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 896027.34it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1128.37it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 939794.76it/s]\n",
      "2022-01-28 16:06:21,231 : INFO : jieba分词已完成\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 59923.76it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 52937.66it/s]\n",
      "2022-01-28 16:06:21,273 : INFO : 特定字符过滤已完成\n",
      "2022-01-28 16:06:21,315 : INFO : onehot已完成\n",
      "/Users/niejikai/Desktop/程序/Pycharm/TextClassification/ModelPreparation/dataset_partition.py:31: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  docvec_array_pure = docvec_array[[pure_index]]\n",
      "/Users/niejikai/Desktop/程序/Pycharm/TextClassification/ModelPreparation/dataset_partition.py:32: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  label_array_pure = label_array[[pure_index]]\n",
      "/Users/niejikai/Desktop/程序/Pycharm/TextClassification/ModelPreparation/dataset_partition.py:42: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  docvec_array_aug = docvec_array[[aug_index]]\n",
      "/Users/niejikai/Desktop/程序/Pycharm/TextClassification/ModelPreparation/dataset_partition.py:43: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  label_array_aug = label_array[[aug_index]]\n",
      "2022-01-28 16:06:25,341 : INFO : 数据拆分已完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.2432 - sparse_categorical_accuracy: 0.5383 - val_loss: 1.2593 - val_sparse_categorical_accuracy: 0.5050\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.1311 - sparse_categorical_accuracy: 0.5683 - val_loss: 1.2515 - val_sparse_categorical_accuracy: 0.5050\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.0859 - sparse_categorical_accuracy: 0.5683 - val_loss: 1.2381 - val_sparse_categorical_accuracy: 0.5050\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 1.0082 - sparse_categorical_accuracy: 0.6467 - val_loss: 1.2879 - val_sparse_categorical_accuracy: 0.4250\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 0.7565 - sparse_categorical_accuracy: 0.7333 - val_loss: 1.4275 - val_sparse_categorical_accuracy: 0.4300\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 0.5637 - sparse_categorical_accuracy: 0.7883 - val_loss: 1.6680 - val_sparse_categorical_accuracy: 0.4450\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 34s 2s/step - loss: 0.4227 - sparse_categorical_accuracy: 0.8567 - val_loss: 1.5957 - val_sparse_categorical_accuracy: 0.4400\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 36s 2s/step - loss: 0.2710 - sparse_categorical_accuracy: 0.9233 - val_loss: 1.9600 - val_sparse_categorical_accuracy: 0.4650\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 33s 2s/step - loss: 0.4724 - sparse_categorical_accuracy: 0.9267 - val_loss: 2.1881 - val_sparse_categorical_accuracy: 0.4400\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 0.1574 - sparse_categorical_accuracy: 0.9617 - val_loss: 1.9960 - val_sparse_categorical_accuracy: 0.4650\n",
      "Model: \"rcnn_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_center (Embedding) multiple                  721200    \n",
      "_________________________________________________________________\n",
      "lstm_forward (LSTM)          multiple                  365568    \n",
      "_________________________________________________________________\n",
      "lstm_backward (LSTM)         multiple                  365568    \n",
      "_________________________________________________________________\n",
      "time_dense (Dense)           multiple                  78464     \n",
      "_________________________________________________________________\n",
      "poolling (GlobalMaxPooling1D multiple                  0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         multiple                  645       \n",
      "=================================================================\n",
      "Total params: 1,531,445\n",
      "Trainable params: 1,531,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pip = Pipeline([TextPreprocess.typeface_transform.char_converter,\n",
    "                TextPreprocess.cut_word.jieba_cut,\n",
    "                TextPreprocess.chartype_filter.number_filter,\n",
    "                TextVector.traditional_vector.one_hot_keras,\n",
    "                ModelPreparation.dataset_partition.split_train_test,\n",
    "                Classifier.deep_learning.train.rcnn])\n",
    "pip_output = pip(input_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f23c8ab6-84ca-4347-8a7b-9290f96d134f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.50s/it]\n"
     ]
    }
   ],
   "source": [
    "pip_outputs = [pip_output]\n",
    "evaluation = Successor.ModelEvaluation(f1_score='micro')\n",
    "evaluation_result = evaluation.run(pip_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52012f71-973a-45ae-9aa0-0664ab73fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Successor.ModelPredict(return_type='class')\n",
    "prediction_result = prediction.run(pip_output['clf_model'], pip_output['docvec_predict_array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6978f779-6cc7-4ad6-bb72-52c65af1a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pkl模型保存方案失败,已切换为keras模型保存方案\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 00:24:51,200 : INFO : Assets written to: /Users/niejikai/Desktop/垃圾文件//rcnn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存在/Users/niejikai/Desktop/垃圾文件//rcnn/\n"
     ]
    }
   ],
   "source": [
    "save = Successor.ModelSave(save_path = os.getcwd()+'/save',name = 'rcnn')\n",
    "save.run(pip_output['clf_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35703045-2926-4d5b-996c-8eeccd4de5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
