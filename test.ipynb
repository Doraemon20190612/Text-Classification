{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74f0e82-b52f-4206-ac39-c130d67ff6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(),\"..\")))\n",
    "from TextClassification import Augment\n",
    "from TextClassification import TextPreprocess\n",
    "from TextClassification import ExtractKeyword\n",
    "from TextClassification import TextVector\n",
    "from TextClassification import FeatureDimensionReduce\n",
    "from TextClassification import FeatureCode\n",
    "from TextClassification import ModelPreparation\n",
    "from TextClassification import Classifier\n",
    "from TextClassification import Successor\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import json\n",
    "from fastcore.transform import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7b7a2-0c5a-4721-a9db-f7d52106754c",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150837a1-94ef-41a0-bf57-5a1be5cbe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getcwd()+'/data/训练集.csv')[:1000]\n",
    "data['feature'] = data['评论标题'].map(str)+data['评论内容'].map(str)\n",
    "data_feature = data['feature']\n",
    "\n",
    "data_predict_origin = pd.read_csv(os.getcwd()+'/data/测试集.csv')[:1000]\n",
    "data_predict_origin['feature'] = data_predict_origin['评论标题'].map(str)+data_predict_origin['评论内容'].map(str)\n",
    "data_predict_feature = data_predict_origin['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f4da67-ed1e-484e-8c97-1e2bafadcf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label对应关系: {4.0: 3, 5.0: 4, 1.0: 0, 3.0: 2, 2.0: 1}\n"
     ]
    }
   ],
   "source": [
    "# 加载label_array\n",
    "data['label'] = preprocessing.LabelEncoder().fit_transform(data['评分'])\n",
    "label_array = np.array(data['label'])\n",
    "# label与类别的映射关系\n",
    "label_map = dict(zip(data['评分'].unique(),preprocessing.LabelEncoder().fit_transform(data['评分'].unique())))\n",
    "print('label对应关系:',label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4e02ad-80e6-4db5-895b-8e3bc3e7397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_cy = list(pd.read_csv(os.getcwd()+'/data/define_stopwords.txt',names = ['word'], \n",
    "                                sep = 'aaa',encoding = 'UTF-8',engine='python').word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb96f148-5971-41e4-a56e-e3ec2ac17312",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_file = open(os.getcwd()+'/data/parameter.json', \"rb\")\n",
    "parameter_json = json.load(parameter_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f938c8d4-d314-4a04-a5a4-f5747b4e10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建input_data\n",
    "input_data = {}\n",
    "input_data['data_feature'] = data_feature\n",
    "input_data['stop_words'] = stopwords_cy\n",
    "input_data['label_array'] = label_array\n",
    "input_data['aug_mark'] = np.array([0 for i in range(len(label_array))])\n",
    "input_data['parameter'] = parameter_json\n",
    "input_data['data_predict_feature'] = data_predict_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9367ec2-7851-4295-a704-d2b686b6b1d6",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995eb6a3-9db0-4fa0-b5c3-759d20fea1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 18:47:31,492 : INFO : 文体转换已完成\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "2022-07-15 18:47:31,507 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/rr/v7xrvjf906q1nz17t5qvls2w0000gn/T/jieba.cache\n",
      "2022-07-15 18:47:31,512 : DEBUG : Loading model from cache /var/folders/rr/v7xrvjf906q1nz17t5qvls2w0000gn/T/jieba.cache\n",
      "Loading model cost 0.684 seconds.\n",
      "2022-07-15 18:47:32,195 : DEBUG : Loading model cost 0.684 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2022-07-15 18:47:32,196 : DEBUG : Prefix dict has been built successfully.\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 657.90it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 961775.74it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1170.05it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 860723.17it/s]\n",
      "2022-07-15 18:47:33,890 : INFO : jieba分词已完成\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 61823.68it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 46302.92it/s]\n",
      "2022-07-15 18:47:33,938 : INFO : 特定字符过滤已完成\n",
      "2022-07-15 18:47:33,986 : INFO : onehot已完成\n",
      "/Users/niejikai/Desktop/程序/Pycharm/TextClassification/ModelPreparation/dataset_partition.py:31: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  docvec_array_pure = docvec_array[[pure_index]]\n",
      "/Users/niejikai/Desktop/程序/Pycharm/TextClassification/ModelPreparation/dataset_partition.py:32: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  label_array_pure = label_array[[pure_index]]\n",
      "/Users/niejikai/Desktop/程序/Pycharm/TextClassification/ModelPreparation/dataset_partition.py:42: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  docvec_array_aug = docvec_array[[aug_index]]\n",
      "/Users/niejikai/Desktop/程序/Pycharm/TextClassification/ModelPreparation/dataset_partition.py:43: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  label_array_aug = label_array[[aug_index]]\n",
      "2022-07-15 18:47:38,001 : INFO : 数据拆分已完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 32s 1s/step - loss: 1.3729 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.2980 - val_sparse_categorical_accuracy: 0.5050\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 35s 2s/step - loss: 1.1358 - sparse_categorical_accuracy: 0.5771 - val_loss: 1.2428 - val_sparse_categorical_accuracy: 0.5050\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.0633 - sparse_categorical_accuracy: 0.5609 - val_loss: 1.2318 - val_sparse_categorical_accuracy: 0.5050\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 35s 2s/step - loss: 1.0319 - sparse_categorical_accuracy: 0.5673 - val_loss: 1.2280 - val_sparse_categorical_accuracy: 0.4800\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 0.8246 - sparse_categorical_accuracy: 0.7073 - val_loss: 1.2621 - val_sparse_categorical_accuracy: 0.4700\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 31s 2s/step - loss: 0.5604 - sparse_categorical_accuracy: 0.8125 - val_loss: 1.3946 - val_sparse_categorical_accuracy: 0.4550\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8808 - val_loss: 6.0802 - val_sparse_categorical_accuracy: 0.2800\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 1.2472 - sparse_categorical_accuracy: 0.7872 - val_loss: 1.5579 - val_sparse_categorical_accuracy: 0.4400\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 0.1844 - sparse_categorical_accuracy: 0.9458 - val_loss: 1.6234 - val_sparse_categorical_accuracy: 0.4700\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 32s 2s/step - loss: 0.1637 - sparse_categorical_accuracy: 0.9737 - val_loss: 1.7180 - val_sparse_categorical_accuracy: 0.4450\n",
      "Model: \"rcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_center (Embedding) multiple                  721200    \n",
      "_________________________________________________________________\n",
      "lstm_forward (LSTM)          multiple                  365568    \n",
      "_________________________________________________________________\n",
      "lstm_backward (LSTM)         multiple                  365568    \n",
      "_________________________________________________________________\n",
      "time_dense (Dense)           multiple                  78464     \n",
      "_________________________________________________________________\n",
      "poolling (GlobalMaxPooling1D multiple                  0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         multiple                  645       \n",
      "=================================================================\n",
      "Total params: 1,531,445\n",
      "Trainable params: 1,531,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pip = Pipeline([TextPreprocess.typeface_transform.char_converter,\n",
    "                TextPreprocess.cut_word.jieba_cut,\n",
    "                TextPreprocess.chartype_filter.number_filter,\n",
    "                TextVector.traditional_vector.one_hot_keras,\n",
    "                ModelPreparation.dataset_partition.split_train_test,\n",
    "                Classifier.deep_learning.train.rcnn])\n",
    "pip_output = pip(input_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f23c8ab6-84ca-4347-8a7b-9290f96d134f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.15s/it]\n"
     ]
    }
   ],
   "source": [
    "pip_outputs = [pip_output]\n",
    "evaluation = Successor.ModelEvaluation(f1_score='micro')\n",
    "evaluation_result = evaluation.run(pip_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52012f71-973a-45ae-9aa0-0664ab73fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Successor.ModelPredict(return_type='class')\n",
    "prediction_result = prediction.run(pip_output['clf_model'], pip_output['docvec_predict_array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6978f779-6cc7-4ad6-bb72-52c65af1a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pkl模型保存方案失败,已切换为keras模型保存方案\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 00:24:51,200 : INFO : Assets written to: /Users/niejikai/Desktop/垃圾文件//rcnn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存在/Users/niejikai/Desktop/垃圾文件//rcnn/\n"
     ]
    }
   ],
   "source": [
    "save = Successor.ModelSave(save_path = os.getcwd()+'/save',name = 'rcnn')\n",
    "save.run(pip_output['clf_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35703045-2926-4d5b-996c-8eeccd4de5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
